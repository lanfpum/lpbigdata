<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>

    <property>
        <name>dfs.blocksize</name>
        <value>128m</value>
    </property>

    <property>>
        <name>dfs.namenode.name.dir</name>
        <value>file:///home/lanp/hadoop/dfs/name1,file:///home/lanp/hadoop/dfs/name2</value>
    </property>

    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///home/lanp/hadoop/dfs/data1,file:///home/lanp/hadoop/dfs/data2</value>
    </property>

    <!-- <property>
            <name>dfs.namenode.secondary.http-address</name>
            <value>ip205:50090</value>
    </property> -->

    <property>
        <name>dfs.hosts</name>
        <value>/soft/hadoop/etc/dfs.include.txt</value>
    </property>

    <property>
        <name>dfs.hosts.exclude</name>
        <value>/soft/hadoop/etc/dfs.hosts.exclude.txt</value>
    </property>

    <!-- ha 配置 -->
    <property>
        <name>dfs.nameservices</name>
        <value>lanpengcluster</value>
    </property>

    <!-- lanpengcluster下的名称节点两个id，注意：当前只允许两个节点 -->
    <property>
        <name>dfs.ha.namenodes.lanpengcluster</name>
        <value>namenode1,namenode2</value>
        <name>dfs.ha.namenodes.lanpengcluster</name>
        <value>namenode1,namenode2</value>
    </property>

    <!--  配置每个nn的rpc地址。  -->
    <property>
        <name>dfs.namenode.rpc-address.lanpengcluster.namenode1</name>
        <value>ip201:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.lanpengcluster.namenode2</name>
        <value>ip205:8020</value>
    </property>

    <!--  配置webui端口  -->
    <property>
        <name>dfs.namenode.http-address.lanpengcluster.namenode1</name>
        <value>ip201:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.lanpengcluster.namenode2</name>
        <value>ip205:50070</value>
    </property>
    <!--  配置名称节点共享编辑目录  -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://ip202:8485;ip203:8485;ip204:8485/lanpengcluster</value>
    </property>
    <!--  java类，client使用它判断哪个节点是激活态  -->
    <property>
        <name>dfs.client.failover.proxy.provider.lanpengcluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!--  脚本列表或者java类，在容灾保护激活态的nn  -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>
            sshfence
            shell(/bin/true)
        </value>
    </property>

    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/lanp/.ssh/id_rsa</value>
    </property>

    <!--  配置JN存放edit的本地路径  -->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/home/lanp/hadoop/journal</value>
    </property>

    <!--  配置自动容灾  -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

</configuration>

